{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set the path to the Tesseract executable (change it based on your installation)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the input image\n",
    "image = cv2.imread(\"../Allen.jpg\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"GrayScale Image\", gray)\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Noise removal function\n",
    "# def noise_removal(image):\n",
    "#     kernel = np.ones((1, 1), np.uint8)\n",
    "#     image = cv2.dilate(image, kernel, iterations=1)\n",
    "#     kernel = np.ones((1, 1), np.uint8)\n",
    "#     image = cv2.erode(image, kernel, iterations=1)\n",
    "#     image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "#     image = cv2.medianBlur(image, 3)\n",
    "#     return (image)\n",
    "\n",
    "# no_noise = noise_removal(gray)\n",
    "# # cv2.imwrite(\"preprocess/no_noise.jpg\", no_noise)\n",
    "\n",
    "# plt.imshow(gray,'gray',vmin=0,vmax=255)\n",
    "# cv2.imshow('Noise Reduction', no_noise)\n",
    "# cv2.imshow(\"GrayScale\", gray)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply thresholding to get a binary image\n",
    "_, binary_image = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "B1 = cv2.adaptiveThreshold(gray, maxValue = 255, adaptiveMethod = cv2.ADAPTIVE_THRESH_GAUSSIAN_C, thresholdType = cv2.THRESH_BINARY, blockSize = 5, C = 15)\n",
    "\n",
    "# Apply morphological operations to remove noise and enhance text regions\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "# processed_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)\n",
    "processed_image = cv2.morphologyEx(kernel, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "cv2.imshow(\"Thresh Image\", binary_image)\n",
    "cv2.imshow(\"Adaptive Thresh\", B1)\n",
    "cv2.imshow(\"Processed image\", processed_image)\n",
    "# cv2.imshow(\"Adaptive Thresh\", B1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find contours in the processed image\n",
    "# contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Iterate through each contour and extract text using Tesseract\n",
    "# for contour in contours:\n",
    "#     x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "#     # Filter out small contours to remove noise\n",
    "#     if cv2.contourArea(contour) > 100:\n",
    "#         # Extract the region of interest (ROI) containing the text\n",
    "#         roi = image[y:y + h, x:x + w]\n",
    "\n",
    "#         # Use Tesseract OCR to extract text from the ROI\n",
    "#         text = pytesseract.image_to_string(roi, config='--psm 6')  # Adjust psm (page segmentation mode) as needed\n",
    "\n",
    "#         # Print the extracted text\n",
    "#         print(\"Extracted Text:\\n\", text)\n",
    "\n",
    "#         # Draw a bounding box around the detected text\n",
    "#         cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      " POU ale suUCH a WONGCTIUL SUT,\n",
      "A gift to keep, a gift to care for\n",
      "and a gift to love now and forever.\n",
      "You are like the heaven's gift.\n",
      "The one I have been hoping for\n",
      "and dreaming about my entire life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#bounding boxes for each text and words\n",
    "# Iterate through each contour and extract text using Tesseract\n",
    "contours, _ = cv2.findContours(processed_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "for contour in contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "    # Filter out small contours to remove noise\n",
    "    if cv2.contourArea(contour) > 100:\n",
    "        # Extract the region of interest (ROI) containing the text\n",
    "        roi = image[y:y + h, x:x + w]\n",
    "        # Use Tesseract OCR to extract text from the ROI\n",
    "        text = pytesseract.image_to_string(roi, config='--psm 6')  # Adjust psm (page segmentation mode) as needed\n",
    "        \n",
    "        # Print the extracted text\n",
    "        print(\"Extracted Text:\\n\", text)\n",
    "        \n",
    "        # Use Tesseract OCR to get individual words or characters\n",
    "        custom_config = r'--oem 3 --psm 6 outputbase digits'\n",
    "        results = pytesseract.image_to_boxes(roi, config=custom_config).splitlines()\n",
    "\n",
    "        # Draw bounding boxes for each word or character\n",
    "        for line in results:\n",
    "            word_data = line.split()\n",
    "            x_start, y_start, x_end, y_end = map(int, word_data[1:5])\n",
    "            \n",
    "            # Draw a bounding box around the word or character\n",
    "            cv2.rectangle(image, (x + x_start, y + y_start), (x + x_end, y + y_end), (0, 255, 0), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image with bounding boxes\n",
    "cv2.imshow('Text Extraction', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
